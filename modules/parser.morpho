// Basic tokenizer

class StringStream {
  init(str) {
    self.str = str
    self.len = str.count() 
    self.n = 0
  }

  readchar() {
    if (self.n>=self.len) return nil 
    var out = self.str[self.n]
    self.n+=1 
    return out
  }

  eof() {
    return (self.n >= self.len)
  }
} 

class Tokenizer {
  init(stream, whitespace=" \n") {
    self.stream = stream // The stream to use
    self.current = self.advance() // Current character

    self.whitespace = Dictionary() // Whitespace characters
    for (c in whitespace) self.whitespace[c] = true
  }

  advance() {
    self.current = self.stream.readchar()
    return self.current
  }

  atend() {
    return self.stream.eof()
  }

  iswhitespace(c) {
    return self.whitespace.contains(c)
  }

  skipwhitespace() {
    while (self.iswhitespace(self.current) && !self.atend()) {
      self.advance()
    }
  }

  next() {
    var token = nil

    self.skipwhitespace()
    while (!self.atend()) {
      var char = self.current
      if (!char) break
      if (self.iswhitespace(char)) break
      if (token) token+=char else token=char
      self.advance()
    }
    return token
  }
}
