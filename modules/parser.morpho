

class Tokenizer {
  init(stream, whitespace=" \n") {
    self.stream = stream // The stream to use
    self.current = self.advance() // Current character

    self.whitespace = Dictionary() // Whitespace characters
    for (c in whitespace) self.whitespace[c] = true
  }

  advance() {
    self.current = self.stream.readchar()
    return self.current
  }

  atend() {
    return self.stream.eof()
  }

  iswhitespace(c) {
    return self.whitespace.contains(c)
  }

  skipwhitespace() {
    while (self.iswhitespace(self.current) && !self.atend()) {
      self.advance()
    }
  }

  next() {
    var token = nil

    self.skipwhitespace()
    while (!self.atend()) {
      var char = self.current
      if (!char) break
      if (self.iswhitespace(char)) break
      if (token) token+=char else token=char
      self.advance()
    }
    return token
  }
}
